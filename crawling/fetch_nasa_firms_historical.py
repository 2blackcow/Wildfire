import os
import requests
import csv
import json
import time
from dotenv import load_dotenv
from datetime import datetime, timedelta

def load_existing_data(path):
    """ê¸°ì¡´ JSON íŒŒì¼ ë¡œë“œ"""
    if not os.path.exists(path):
        return []
    with open(path, "r", encoding="utf-8") as f:
        try:
            return json.load(f)
        except:
            return []

def fetch_firms_historical_range():
    """2024-10-01ë¶€í„° 2025-04-01ê¹Œì§€ NASA FIRMS ë°ì´í„° ìˆ˜ì§‘"""
    
    # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    dotenv_path = os.path.abspath(os.path.join(__file__, "..", "..", ".env"))
    load_dotenv(dotenv_path)
    map_key = os.getenv("FIRMS_KEY") or "d4c10c572f34e93458cca9cd34424991"

    if not map_key:
        print("âŒ FIRMS_KEY ëˆ„ë½ë¨")
        return

    # ê¸°ê°„ ì„¤ì •
    start_date = datetime(2024, 10, 1)
    end_date = datetime(2025, 4, 1)
    
    source = "VIIRS_SNPP_NRT"
    bbox = "124,33,132,39"  # í•œêµ­ ì˜ì—­
    
    print(f"ğŸ›°ï¸ NASA FIRMS ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    print(f"ğŸ“… ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")
    print(f"ğŸ—ºï¸ ì˜ì—­: {bbox} (í•œêµ­)")

    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    base_dir = os.path.abspath(os.path.join(__file__, "..", ".."))
    save_path = os.path.join(base_dir, "public", "data", "nasa_firms_korea_2024_2025.json")
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
    # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
    existing_data = load_existing_data(save_path)
    existing_set = {json.dumps(entry, sort_keys=True) for entry in existing_data}
    
    print(f"ğŸ“‚ ê¸°ì¡´ ë°ì´í„°: {len(existing_data)}ê±´")

    all_new_data = []
    current_date = start_date
    request_count = 0
    
    # 10ì¼ì”© ë‚˜ëˆ„ì–´ ìš”ì²­ (API ì œí•œ)
    while current_date < end_date:
        # 10ì¼ ë²”ìœ„ ê³„ì‚°
        range_end = min(current_date + timedelta(days=9), end_date - timedelta(days=1))
        
        # ë‚ ì§œ í¬ë§· ë³€í™˜ (YYYY-MM-DD)
        date_start_str = current_date.strftime("%Y-%m-%d")
        date_end_str = range_end.strftime("%Y-%m-%d")
        
        # API URL ìƒì„± (ë‚ ì§œ ë²”ìœ„ ì§€ì •)
        url = f"https://firms.modaps.eosdis.nasa.gov/api/area/csv/{map_key}/{source}/{bbox}/1/{date_start_str}"
        
        print(f"\nğŸ“¡ ìš”ì²­ {request_count + 1}: {date_start_str} ~ {date_end_str}")
        print(f"ğŸŒ URL: {url}")

        try:
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            
            # CSV íŒŒì‹±
            decoded = response.content.decode("utf-8").splitlines()
            reader = csv.DictReader(decoded)
            range_data = list(reader)
            
            # ë‚ ì§œ í•„í„°ë§ (APIê°€ ì •í™•í•œ ë‚ ì§œ ë²”ìœ„ë¥¼ ë³´ì¥í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ)
            filtered_data = []
            for entry in range_data:
                try:
                    entry_date = datetime.strptime(entry["acq_date"], "%Y-%m-%d")
                    if current_date <= entry_date <= range_end:
                        filtered_data.append(entry)
                except (ValueError, KeyError):
                    continue
            
            print(f"ğŸ“¥ ìˆ˜ì‹ : {len(range_data)}ê±´ â†’ í•„í„°ë§ í›„: {len(filtered_data)}ê±´")
            all_new_data.extend(filtered_data)
            
            request_count += 1
            
            # API ë¶€í•˜ ë°©ì§€ (1ì´ˆ ëŒ€ê¸°)
            time.sleep(1)
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ API ìš”ì²­ ì˜¤ë¥˜ ({date_start_str}): {e}")
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜ ({date_start_str}): {e}")
        
        # ë‹¤ìŒ 10ì¼ë¡œ ì´ë™
        current_date = range_end + timedelta(days=1)

    print(f"\nğŸ”„ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ: {len(all_new_data)}ê±´")

    # ì¤‘ë³µ ì œê±°
    unique_new_data = []
    for entry in all_new_data:
        entry_json = json.dumps(entry, sort_keys=True)
        if entry_json not in existing_set:
            unique_new_data.append(entry)
            existing_set.add(entry_json)

    # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©
    combined_data = existing_data + unique_new_data
    
    # ë‚ ì§œìˆœ ì •ë ¬
    def get_date_key(entry):
        try:
            date_str = entry.get("acq_date", "")
            time_str = entry.get("acq_time", "0000")
            datetime_str = f"{date_str} {time_str[:2]}:{time_str[2:]}"
            return datetime.strptime(datetime_str, "%Y-%m-%d %H:%M")
        except:
            return datetime.min
    
    combined_data.sort(key=get_date_key)

    # íŒŒì¼ ì €ì¥
    with open(save_path, "w", encoding="utf-8") as f:
        json.dump(combined_data, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ì €ì¥ ì™„ë£Œ!")
    print(f"ğŸ“ íŒŒì¼ ìœ„ì¹˜: {save_path}")
    print(f"ğŸ“Š ì‹ ê·œ ë°ì´í„°: {len(unique_new_data)}ê±´")
    print(f"ğŸ“Š ì „ì²´ ë°ì´í„°: {len(combined_data)}ê±´")
    print(f"ğŸŒ ì´ API ìš”ì²­: {request_count}íšŒ")

    # ì›”ë³„ í†µê³„
    monthly_stats = {}
    for entry in combined_data:
        try:
            date_str = entry.get("acq_date", "")
            if len(date_str) >= 7:
                month_key = date_str[:7]  # YYYY-MM
                monthly_stats[month_key] = monthly_stats.get(month_key, 0) + 1
        except:
            continue

    print(f"\nğŸ“ˆ ì›”ë³„ NASA í™”ì¬ ê°ì§€ í†µê³„:")
    for month in sorted(monthly_stats.keys()):
        count = monthly_stats[month]
        print(f"  {month}: {count:4d}ê±´")

    # ì‹ ë¢°ë„ë³„ í†µê³„
    confidence_stats = {}
    brightness_values = []
    
    for entry in combined_data:
        conf = entry.get("confidence", "unknown")
        confidence_stats[conf] = confidence_stats.get(conf, 0) + 1
        
        try:
            brightness = float(entry.get("brightness", 0))
            if brightness > 0:
                brightness_values.append(brightness)
        except:
            pass

    print(f"\nğŸ¯ ì‹ ë¢°ë„ë³„ ë¶„í¬:")
    for conf in sorted(confidence_stats.keys()):
        count = confidence_stats[conf]
        print(f"  {conf}: {count:4d}ê±´")

    if brightness_values:
        avg_brightness = sum(brightness_values) / len(brightness_values)
        print(f"\nğŸ”† í‰ê·  ë°ê¸°: {avg_brightness:.1f}K")

if __name__ == "__main__":
    fetch_firms_historical_range()